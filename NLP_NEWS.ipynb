{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_NEWS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singularity014/BERT_FakeNews_Detection_Challenge/blob/master/NLP_NEWS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxkyIyiJo-V4",
        "colab_type": "text"
      },
      "source": [
        "## I - Problem Statement\n",
        "\n",
        "- **Given** - A Data Set of Fake and Real news.\n",
        "\n",
        "- **Objective** - To develop a solution which  \n",
        "  detects if a given news is Fake or Real.\n",
        "\n",
        "- **Methodology used** - We try to pose the    problem as a text classification problem and build a deep learning model for achieving the objective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MK4gK3BqRkp",
        "colab_type": "text"
      },
      "source": [
        "#### Different Models - \n",
        "While there multiple types of models which could be used for building the solution for Text Classification. Some Examples are - \n",
        "\n",
        "\n",
        "*   **1D- Conv Net** - \n",
        "Yes, CNNs could also be used for text. **Advantage**: They are faster to ttrain. In fact given proper label, a CNN model could achieve decent accuracy **Disdvantage**: They fail to capture long term dependencies in Text, and doesnt not capture sequential information in text.\n",
        "\n",
        "*   **RNN based models (LSTM, GRU) ** -  **Advantage** : They focus on considering words T each time step, encoding them by some non-linear calculation and then taking a decision. In simple words, they can capture sequential nature of a Text. \n",
        "Disadvantage - Slower to train, focus is more on sequential nature, and less on attention mechanism.\n",
        "\n",
        "* **Transformer based Models(BERT, GPT2)**- \n",
        "Transformer based models are a breaktrhough in NLP, and tend to model. Which leverages multiple Transformer units, and a multi-headed attention mechanism. The advantage is that they focus only on attention mechanism. Thus we obtain a model, which is can used in context heavy applications.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKNIwRZ2wqvN",
        "colab_type": "text"
      },
      "source": [
        "## II - STandAlone BERT Model -  \n",
        "\n",
        "- For our solution we will be using BERT model to develop Fake News or Real News Classification Solution. \n",
        "\n",
        "- We achieved an accuracy of 95+ % on test set, and a remarkable AUC by a standalone BERT Model. More improvements could be done with better tuning, and training for longer time. In cloud settings like Google Cloud(with larger GPUs) or AWS infra. But improvement is a continuous process :)\n",
        "\n",
        "- We build an MVP with BERT Stand-alone model\n",
        "\n",
        "- We can Also use, BERT (as an embedder) + LSTM model to build this solution. \n",
        "\n",
        "![alt text](https://lh3.googleusercontent.com/proxy/P18CTUGzSZSRWahZaJ-o3396dcWZZ7-CKWiTSM0oHf6FR7m_LWWKjRZ6hIArUKegAgd1e2zd01q7gySzmBMoEaK9V7A4TMUckvtRf0cSq6oukgE)\n",
        "\n",
        "Above figure shows the Kind of model we will be building in developing our solution.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zfDOSGaijXW",
        "colab_type": "text"
      },
      "source": [
        "## III - Coding Environment  \n",
        "\n",
        "- I chose Google Colab to document the process step by step, other than this I wanted to leverage the free GPU available in Google Colab.\n",
        "- It helped me train faster, compared to my own PC.\n",
        "- In production as well, GPU powered AWS frameweorks such as AWS Sagemkaer and Google GPU cloud infra are useful in training models and deploying quicker. \n",
        "- For coding environment we can develop models\n",
        "  using Keras or Tensorflow. Depending upon    \n",
        "  the level of control we want on model \n",
        "  creation, we can work with that TF versions. \n",
        "\n",
        "- For more control and inner workings of     \n",
        "  model, TF core comes is usually very useful, \n",
        "  and for quicker prototyping we can go for  \n",
        "  Keras or  TF2.0 which is keras style.\n",
        "\n",
        "- For current solution, we can choose any of   \n",
        "  the environment mentioned above, but I chose \n",
        "  to go with TF1.x for better control and   \n",
        "  develop BERT TF.2.0 model for classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oe2027iootyT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47e86436-8eae-4b5b-b1b9-688c9f38e366"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9Lml7fdfCgq",
        "colab_type": "text"
      },
      "source": [
        "## IV - Dependencies and BERT packages\n",
        "\n",
        "\n",
        "*   We will mount the Google Drive to colab environment.\n",
        "*   We will install BERT dependencies.\n",
        "*   Import the necessary packages for developing model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OjZsKvoUpEYh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "f710cdf7-1497-4af2-8230-8ef7cbb6282e"
      },
      "source": [
        "# Mounting Drive\n",
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PqV-l5Zkc2DE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "fc3c6533-f878-4798-d500-f31f5b6d361b"
      },
      "source": [
        "# Installing BERT module\n",
        "!pip install bert-tensorflow\n",
        "# !pip install bert-for-tf2\n",
        "# !pip install sentencepiece"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ecpn07JdpQuq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2ed36b4a-edf5-4b1b-fbc7-0b97a58ab99d"
      },
      "source": [
        "# Import packages\n",
        "#------------ Utilities ---------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.utils import shuffle\n",
        "import nltk\n",
        "\n",
        "# ---------- Tensorflow dependencies--------------------\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "# ---------- BERT ------------\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nyJZquOOp61-",
        "colab": {}
      },
      "source": [
        "df_fktest=pd.read_json('https://storage.googleapis.com/public-resources/dataset/fake_test.json')\n",
        "df_fktrain=pd.read_json('https://storage.googleapis.com/public-resources/dataset/fake_train.json')\n",
        "df_realtest=pd.read_json('https://storage.googleapis.com/public-resources/dataset/real_test.json')\n",
        "df_realtrain=pd.read_json('https://storage.googleapis.com/public-resources/dataset/real_train.json')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nhvOM5zGqdgM",
        "colab": {}
      },
      "source": [
        "df_realtrain2=df_realtrain\n",
        "df_realtest2=df_realtest\n",
        "df_fktrain2=df_fktrain\n",
        "df_fktest2=df_fktest"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xuk9MQtsqJQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "814f14be-9b6c-454f-9945-6e739ea58ee8"
      },
      "source": [
        "print(df_fktest.shape)\n",
        "print(df_fktrain.shape)\n",
        "print(df_realtest.shape)\n",
        "print(df_realtrain.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 3)\n",
            "(800, 3)\n",
            "(200, 3)\n",
            "(800, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zp5Sr-0_qiOT",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def clean_txt(text):\n",
        "    text = re.sub(\"'\", \"\",text)\n",
        "    text=re.sub(\"(\\\\W)+\",\" \",text)    \n",
        "    return text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kOnIcePiqmAY",
        "colab": {}
      },
      "source": [
        "df_fktrain['text']  = df_fktrain.text.apply(clean_txt)\n",
        "df_fktest['text']  = df_fktest.text.apply(clean_txt)\n",
        "df_realtest['text']  = df_realtest.text.apply(clean_txt)\n",
        "df_realtrain['text']  = df_realtrain.text.apply(clean_txt)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3wkWZGS4qonS",
        "colab": {}
      },
      "source": [
        "def get_split(text1):\n",
        "    l_total = []\n",
        "    l_parcial = []\n",
        "    if len(text1.split())//150 >0:\n",
        "        n = len(text1.split())//150\n",
        "    else: \n",
        "        n = 1\n",
        "    for w in range(n):\n",
        "        if w == 0:\n",
        "            l_parcial = text1.split()[:200]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "        else:\n",
        "            l_parcial = text1.split()[w*150:w*150 + 200]\n",
        "            l_total.append(\" \".join(l_parcial))\n",
        "    return l_total"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2HAmR268qrbR",
        "colab": {}
      },
      "source": [
        "df_fktest['text_split'] = df_fktest['text'].apply(get_split)\n",
        "df_fktrain['text_split'] = df_fktrain['text'].apply(get_split)\n",
        "df_realtest['text_split'] = df_realtest['text'].apply(get_split)\n",
        "df_realtrain['text_split'] = df_realtrain['text'].apply(get_split)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rew3xtylquO_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "99056d06-93a0-4733-d68c-159dcc9d06de"
      },
      "source": [
        "print(df_fktest['text_split'].isnull().sum())\n",
        "print(df_fktrain['text_split'].isnull().sum())\n",
        "print(df_realtest['text_split'].isnull().sum())\n",
        "print(df_realtrain['text_split'].isnull().sum())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rU7kiwDCqxIv",
        "colab": {}
      },
      "source": [
        "df_fktrain['is_fake'] = 1\n",
        "df_fktest['is_fake'] = 1\n",
        "df_realtest['is_fake'] = 0\n",
        "df_realtrain['is_fake'] = 0"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rHvty9ibq1Bw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49405b56-4824-4cd9-f55e-7fcd5028c4a5"
      },
      "source": [
        "train_data = pd.concat([df_fktrain, df_realtrain])\n",
        "test_data = pd.concat([df_fktest, df_realtest])\n",
        "\n",
        "\n",
        "\n",
        "# Shuffle the data\n",
        "train_data = shuffle(train_data).reset_index(drop=True)\n",
        "train_data.head(100)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>text_split</th>\n",
              "      <th>is_fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://arabic.rt.com/videoclub/1094755-%D8%B1...</td>\n",
              "      <td>Russia repelled the most dangerous epidemic of...</td>\n",
              "      <td>Russia repelled the most dangerous epidemic of...</td>\n",
              "      <td>[Russia repelled the most dangerous epidemic o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.theguardian.com/world/2020/feb/25/...</td>\n",
              "      <td>Iran deputy health minister : I have coronavirus</td>\n",
              "      <td>Irans deputy health minister I have coronaviru...</td>\n",
              "      <td>[Irans deputy health minister I have coronavir...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://lv.sputniknews.ru/Latvia/20200315/1337...</td>\n",
              "      <td>Coronavirus invented in Latvia? Why not</td>\n",
              "      <td>Of course the application of the old Roman rul...</td>\n",
              "      <td>[Of course the application of the old Roman ru...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.theatlantic.com/health/archive/202...</td>\n",
              "      <td>Why COVID - 19 Makes Some People Sicker Than O...</td>\n",
              "      <td>The COVID 19 crash comes suddenly In early Mar...</td>\n",
              "      <td>[The COVID 19 crash comes suddenly In early Ma...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.khabarlb.com/world/khabar102875.html</td>\n",
              "      <td>The mystery of the virus that slept 5 years .....</td>\n",
              "      <td>Russia Today has published an article about t...</td>\n",
              "      <td>[Russia Today has published an article about t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>https://arabic.sputniknews.com/radio_between_t...</td>\n",
              "      <td>What is the truth behind the existence of a bi...</td>\n",
              "      <td>In response US Secretary of State Mike Pompeo ...</td>\n",
              "      <td>[In response US Secretary of State Mike Pompeo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>https://news.err.ee/1071565/reinsalu-thanks-uk...</td>\n",
              "      <td>Reinsalu thanks united kingdom and Belarus for...</td>\n",
              "      <td>Reinsalu thanks UK and Belarus for helping Est...</td>\n",
              "      <td>[Reinsalu thanks UK and Belarus for helping Es...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>https://hathalyoum.net/articles/2292576-%D9%84...</td>\n",
              "      <td>Coronary virus puzzle that slept 5 years!</td>\n",
              "      <td>Coronary virus puzzle that slept 5 years This ...</td>\n",
              "      <td>[Coronary virus puzzle that slept 5 years This...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>https://sudanway.com/2020/02/03/%D8%A7%D9%84%D...</td>\n",
              "      <td>Yellow skin is the host environment of the vir...</td>\n",
              "      <td>In a report published by the American Forbes m...</td>\n",
              "      <td>[In a report published by the American Forbes ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>https://www.saadaonline.net/arab-news/2699075/...</td>\n",
              "      <td>Russia is completing the first stage of manufa...</td>\n",
              "      <td>We show you our visitors the most important an...</td>\n",
              "      <td>[We show you our visitors the most important a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  url  ... is_fake\n",
              "0   https://arabic.rt.com/videoclub/1094755-%D8%B1...  ...       1\n",
              "1   https://www.theguardian.com/world/2020/feb/25/...  ...       0\n",
              "2   https://lv.sputniknews.ru/Latvia/20200315/1337...  ...       1\n",
              "3   https://www.theatlantic.com/health/archive/202...  ...       0\n",
              "4    https://www.khabarlb.com/world/khabar102875.html  ...       1\n",
              "..                                                ...  ...     ...\n",
              "95  https://arabic.sputniknews.com/radio_between_t...  ...       1\n",
              "96  https://news.err.ee/1071565/reinsalu-thanks-uk...  ...       0\n",
              "97  https://hathalyoum.net/articles/2292576-%D9%84...  ...       1\n",
              "98  https://sudanway.com/2020/02/03/%D8%A7%D9%84%D...  ...       1\n",
              "99  https://www.saadaonline.net/arab-news/2699075/...  ...       1\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xN7ewgH4q3zr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05b7255c-4ae3-45d4-ca68-e95cb5255c04"
      },
      "source": [
        "train_l = []\n",
        "label_l = []\n",
        "index_l =[]\n",
        "for idx,row in train_data.iterrows():\n",
        "    for l in row['text_split']:\n",
        "        train_l.append(l)\n",
        "        label_l.append(row['is_fake'])\n",
        "        index_l.append(idx)\n",
        "len(train_l), len(label_l), len(index_l)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5481, 5481, 5481)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lbXEgIIcfCBd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b3c35d5c-b092-40ee-fe19-68fdf9e30cd0"
      },
      "source": [
        "test_l = []\n",
        "label_l2 = []\n",
        "index_l2 =[]\n",
        "for idx,row in test_data.iterrows():\n",
        "    for l in row['text_split']:\n",
        "        test_l.append(l)\n",
        "        label_l2.append(row['is_fake'])\n",
        "        index_l2.append(idx)\n",
        "len(test_l), len(label_l2), len(index_l2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1230, 1230, 1230)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v6I4axCAs-Gf",
        "colab": {}
      },
      "source": [
        "train_df = pd.DataFrame({'text':train_l, 'label':label_l})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GbfI7QYle6AO",
        "colab": {}
      },
      "source": [
        "test_df = pd.DataFrame({'text':test_l, 'label':label_l2})"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5QVvt8tytBks",
        "colab": {}
      },
      "source": [
        "\n",
        "train_InputExamples = train_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                   text_a = x['text'], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x['label']), axis = 1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HDS2bxr-eyCS",
        "colab": {}
      },
      "source": [
        "test_InputExamples = test_df.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                   text_a = x['text'], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x['label']), axis = 1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnW397UGdbxZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "06ba5c2a-c49e-4c53-a73b-e99c9b271d56"
      },
      "source": [
        " \n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rkTHutEag3i7",
        "colab": {}
      },
      "source": [
        "label_list = [x for x in np.unique(train_data.is_fake)]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mSkm4hVNeuld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc9f5154-a647-4261-a0df-833c2fb93a87"
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 5481\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] russia rep ##elled the most dangerous epidemic of corona videos in 1960 the authorities of the soviet union were able to prevent the spread of the smallpox epidemic through swift measures that contained the epidemic and spared the country a humanitarian catastrophe it used security forces to qu ##aran ##tine more than 10 000 people in moscow in one week and stopped flights trains and cars will countries today be able to tackle corona as the soviet union did 60 years ago [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] russia rep ##elled the most dangerous epidemic of corona videos in 1960 the authorities of the soviet union were able to prevent the spread of the smallpox epidemic through swift measures that contained the epidemic and spared the country a humanitarian catastrophe it used security forces to qu ##aran ##tine more than 10 000 people in moscow in one week and stopped flights trains and cars will countries today be able to tackle corona as the soviet union did 60 years ago [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3607 16360 21148 1996 2087 4795 16311 1997 21887 6876 1999 3624 1996 4614 1997 1996 3354 2586 2020 2583 2000 4652 1996 3659 1997 1996 25765 16311 2083 9170 5761 2008 4838 1996 16311 1998 16891 1996 2406 1037 11470 25539 2009 2109 3036 2749 2000 24209 20486 10196 2062 2084 2184 2199 2111 1999 4924 1999 2028 2733 1998 3030 7599 4499 1998 3765 2097 3032 2651 2022 2583 2000 11147 21887 2004 1996 3354 2586 2106 3438 2086 3283 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3607 16360 21148 1996 2087 4795 16311 1997 21887 6876 1999 3624 1996 4614 1997 1996 3354 2586 2020 2583 2000 4652 1996 3659 1997 1996 25765 16311 2083 9170 5761 2008 4838 1996 16311 1998 16891 1996 2406 1037 11470 25539 2009 2109 3036 2749 2000 24209 20486 10196 2062 2084 2184 2199 2111 1999 4924 1999 2028 2733 1998 3030 7599 4499 1998 3765 2097 3032 2651 2022 2583 2000 11147 21887 2004 1996 3354 2586 2106 3438 2086 3283 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] iran ##s deputy health minister i have corona ##virus fever ##ish ira ##j hari ##rch ##i says disease doesn t distinguish between statesman and ordinary citizen iran s deputy health minister said he has contracted the corona ##virus and placed himself in isolation a day after appearing fever ##ish at a press conference in which he down ##play ##ed its spread in the shrine city of q ##om and said mass qu ##aran ##tine ##s were unnecessary ira ##j hari ##rch ##i posted a video on social media on tuesday acknowledging he had caught the virus which appears to be taking rapid hold in parts of iran the news has under ##sco ##red widespread fears that the outbreak may have passed a tipping point before authorities [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] iran ##s deputy health minister i have corona ##virus fever ##ish ira ##j hari ##rch ##i says disease doesn t distinguish between statesman and ordinary citizen iran s deputy health minister said he has contracted the corona ##virus and placed himself in isolation a day after appearing fever ##ish at a press conference in which he down ##play ##ed its spread in the shrine city of q ##om and said mass qu ##aran ##tine ##s were unnecessary ira ##j hari ##rch ##i posted a video on social media on tuesday acknowledging he had caught the virus which appears to be taking rapid hold in parts of iran the news has under ##sco ##red widespread fears that the outbreak may have passed a tipping point before authorities [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4238 2015 4112 2740 2704 1045 2031 21887 23350 9016 4509 11209 3501 21291 11140 2072 2758 4295 2987 1056 10782 2090 17689 1998 6623 6926 4238 1055 4112 2740 2704 2056 2002 2038 11016 1996 21887 23350 1998 2872 2370 1999 12477 1037 2154 2044 6037 9016 4509 2012 1037 2811 3034 1999 2029 2002 2091 13068 2098 2049 3659 1999 1996 9571 2103 1997 1053 5358 1998 2056 3742 24209 20486 10196 2015 2020 14203 11209 3501 21291 11140 2072 6866 1037 2678 2006 2591 2865 2006 9857 21894 2002 2018 3236 1996 7865 2029 3544 2000 2022 2635 5915 2907 1999 3033 1997 4238 1996 2739 2038 2104 9363 5596 6923 10069 2008 1996 8293 2089 2031 2979 1037 25486 2391 2077 4614 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4238 2015 4112 2740 2704 1045 2031 21887 23350 9016 4509 11209 3501 21291 11140 2072 2758 4295 2987 1056 10782 2090 17689 1998 6623 6926 4238 1055 4112 2740 2704 2056 2002 2038 11016 1996 21887 23350 1998 2872 2370 1999 12477 1037 2154 2044 6037 9016 4509 2012 1037 2811 3034 1999 2029 2002 2091 13068 2098 2049 3659 1999 1996 9571 2103 1997 1053 5358 1998 2056 3742 24209 20486 10196 2015 2020 14203 11209 3501 21291 11140 2072 6866 1037 2678 2006 2591 2865 2006 9857 21894 2002 2018 3236 1996 7865 2029 3544 2000 2022 2635 5915 2907 1999 3033 1997 4238 1996 2739 2038 2104 9363 5596 6923 10069 2008 1996 8293 2089 2031 2979 1037 25486 2391 2077 4614 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] county reeling from its rapid onset in the short video hi ##rac ##hi acknowledged that many may get infected echoing concerns that have taken root in the rest of the middle east which is home to millions of people living in densely packed refugee camps i wanted to tell you that i got corona said hari ##rch ##i i had a fever yesterday the tests came back positive last night i isolated myself just a few moments ago i was told that the final test came i ll start taking medicine generally i feel fine i just felt a bit tired i had a fever and it will drop be sure with the effort of the medical staff and ministry of health headed by the health [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] county reeling from its rapid onset in the short video hi ##rac ##hi acknowledged that many may get infected echoing concerns that have taken root in the rest of the middle east which is home to millions of people living in densely packed refugee camps i wanted to tell you that i got corona said hari ##rch ##i i had a fever yesterday the tests came back positive last night i isolated myself just a few moments ago i was told that the final test came i ll start taking medicine generally i feel fine i just felt a bit tired i had a fever and it will drop be sure with the effort of the medical staff and ministry of health headed by the health [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2221 28515 2013 2049 5915 14447 1999 1996 2460 2678 7632 22648 4048 8969 2008 2116 2089 2131 10372 17142 5936 2008 2031 2579 7117 1999 1996 2717 1997 1996 2690 2264 2029 2003 2188 2000 8817 1997 2111 2542 1999 19441 8966 13141 7958 1045 2359 2000 2425 2017 2008 1045 2288 21887 2056 21291 11140 2072 1045 2018 1037 9016 7483 1996 5852 2234 2067 3893 2197 2305 1045 7275 2870 2074 1037 2261 5312 3283 1045 2001 2409 2008 1996 2345 3231 2234 1045 2222 2707 2635 4200 3227 1045 2514 2986 1045 2074 2371 1037 2978 5458 1045 2018 1037 9016 1998 2009 2097 4530 2022 2469 2007 1996 3947 1997 1996 2966 3095 1998 3757 1997 2740 3753 2011 1996 2740 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2221 28515 2013 2049 5915 14447 1999 1996 2460 2678 7632 22648 4048 8969 2008 2116 2089 2131 10372 17142 5936 2008 2031 2579 7117 1999 1996 2717 1997 1996 2690 2264 2029 2003 2188 2000 8817 1997 2111 2542 1999 19441 8966 13141 7958 1045 2359 2000 2425 2017 2008 1045 2288 21887 2056 21291 11140 2072 1045 2018 1037 9016 7483 1996 5852 2234 2067 3893 2197 2305 1045 7275 2870 2074 1037 2261 5312 3283 1045 2001 2409 2008 1996 2345 3231 2234 1045 2222 2707 2635 4200 3227 1045 2514 2986 1045 2074 2371 1037 2978 5458 1045 2018 1037 9016 1998 2009 2097 4530 2022 2469 2007 1996 3947 1997 1996 2966 3095 1998 3757 1997 2740 3753 2011 1996 2740 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] m saying this deep from my heart this virus is democratic and it doesn t distinguish between poor and rich or statesman and an ordinary citizen many might get infected but we have enough effective medicine take care of yourselves take care of the nurses and doctors who work heroic ##ally iran has become the regional focal point of fears surrounding corona ##virus neighbouring states have largely shut their borders and suspended pilgrimage routes schools and universities in many parts of the country have been closed four new cases were suspected to have been diagnosed in the iraqi city of kirk ##uk on tuesday if confirmed it would take the national tally to five cases a number that is widely expected to rise possibly substantially in [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] m saying this deep from my heart this virus is democratic and it doesn t distinguish between poor and rich or statesman and an ordinary citizen many might get infected but we have enough effective medicine take care of yourselves take care of the nurses and doctors who work heroic ##ally iran has become the regional focal point of fears surrounding corona ##virus neighbouring states have largely shut their borders and suspended pilgrimage routes schools and universities in many parts of the country have been closed four new cases were suspected to have been diagnosed in the iraqi city of kirk ##uk on tuesday if confirmed it would take the national tally to five cases a number that is widely expected to rise possibly substantially in [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1049 3038 2023 2784 2013 2026 2540 2023 7865 2003 3537 1998 2009 2987 1056 10782 2090 3532 1998 4138 2030 17689 1998 2019 6623 6926 2116 2453 2131 10372 2021 2057 2031 2438 4621 4200 2202 2729 1997 25035 2202 2729 1997 1996 11500 1998 7435 2040 2147 14779 3973 4238 2038 2468 1996 3164 15918 2391 1997 10069 4193 21887 23350 9632 2163 2031 4321 3844 2037 6645 1998 6731 14741 5847 2816 1998 5534 1999 2116 3033 1997 1996 2406 2031 2042 2701 2176 2047 3572 2020 6878 2000 2031 2042 11441 1999 1996 8956 2103 1997 11332 6968 2006 9857 2065 4484 2009 2052 2202 1996 2120 19552 2000 2274 3572 1037 2193 2008 2003 4235 3517 2000 4125 4298 12381 1999 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1049 3038 2023 2784 2013 2026 2540 2023 7865 2003 3537 1998 2009 2987 1056 10782 2090 3532 1998 4138 2030 17689 1998 2019 6623 6926 2116 2453 2131 10372 2021 2057 2031 2438 4621 4200 2202 2729 1997 25035 2202 2729 1997 1996 11500 1998 7435 2040 2147 14779 3973 4238 2038 2468 1996 3164 15918 2391 1997 10069 4193 21887 23350 9632 2163 2031 4321 3844 2037 6645 1998 6731 14741 5847 2816 1998 5534 1999 2116 3033 1997 1996 2406 2031 2042 2701 2176 2047 3572 2020 6878 2000 2031 2042 11441 1999 1996 8956 2103 1997 11332 6968 2006 9857 2065 4484 2009 2052 2202 1996 2120 19552 2000 2274 3572 1037 2193 2008 2003 4235 3517 2000 4125 4298 12381 1999 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] of course the application of the old roman rule of seek out who is profitable is almost always fault ##less but in the case of the causes of the occurrence and spread of the corona ##virus on the planet here it is understood that what is as difficult as s ##nee ##zing on the elbow which is what the responsible authorities are calling for either because the one to whom it is not profitable or vice versa there are too many of them as evidenced by the abundance of versions one is more plausible someone claims that the chinese communist party was profitable with co ##vid 19 to stop months long protests in hong kong at the same time with its help you can stop the [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] of course the application of the old roman rule of seek out who is profitable is almost always fault ##less but in the case of the causes of the occurrence and spread of the corona ##virus on the planet here it is understood that what is as difficult as s ##nee ##zing on the elbow which is what the responsible authorities are calling for either because the one to whom it is not profitable or vice versa there are too many of them as evidenced by the abundance of versions one is more plausible someone claims that the chinese communist party was profitable with co ##vid 19 to stop months long protests in hong kong at the same time with its help you can stop the [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1997 2607 1996 4646 1997 1996 2214 3142 3627 1997 6148 2041 2040 2003 15282 2003 2471 2467 6346 3238 2021 1999 1996 2553 1997 1996 5320 1997 1996 14404 1998 3659 1997 1996 21887 23350 2006 1996 4774 2182 2009 2003 5319 2008 2054 2003 2004 3697 2004 1055 24045 6774 2006 1996 8999 2029 2003 2054 1996 3625 4614 2024 4214 2005 2593 2138 1996 2028 2000 3183 2009 2003 2025 15282 2030 3580 18601 2045 2024 2205 2116 1997 2068 2004 21328 2011 1996 14531 1997 4617 2028 2003 2062 24286 2619 4447 2008 1996 2822 4750 2283 2001 15282 2007 2522 17258 2539 2000 2644 2706 2146 8090 1999 4291 4290 2012 1996 2168 2051 2007 2049 2393 2017 2064 2644 1996 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1997 2607 1996 4646 1997 1996 2214 3142 3627 1997 6148 2041 2040 2003 15282 2003 2471 2467 6346 3238 2021 1999 1996 2553 1997 1996 5320 1997 1996 14404 1998 3659 1997 1996 21887 23350 2006 1996 4774 2182 2009 2003 5319 2008 2054 2003 2004 3697 2004 1055 24045 6774 2006 1996 8999 2029 2003 2054 1996 3625 4614 2024 4214 2005 2593 2138 1996 2028 2000 3183 2009 2003 2025 15282 2030 3580 18601 2045 2024 2205 2116 1997 2068 2004 21328 2011 1996 14531 1997 4617 2028 2003 2062 24286 2619 4447 2008 1996 2822 4750 2283 2001 15282 2007 2522 17258 2539 2000 2644 2706 2146 8090 1999 4291 4290 2012 1996 2168 2051 2007 2049 2393 2017 2064 2644 1996 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 1230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 1230\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the post global order is something inevitable the crisis that humanity is going through following the corona ##virus pan ##de ##mic has taken on such a global dimension that a return to the pre existing situation is simply impossible if the spread of the virus is not stopped within a month and a half two months the phenomenon will become ir ##re ##vers ##ible and overnight the whole world order will collapse history has seen similar periods that have been associated with global scale disasters wars and other extraordinary circumstances if we try to look to the future without pre ##con ##ception ##s and in an open way we can fore ##see some of the general scenarios or individual moments that are more likely to occur [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the post global order is something inevitable the crisis that humanity is going through following the corona ##virus pan ##de ##mic has taken on such a global dimension that a return to the pre existing situation is simply impossible if the spread of the virus is not stopped within a month and a half two months the phenomenon will become ir ##re ##vers ##ible and overnight the whole world order will collapse history has seen similar periods that have been associated with global scale disasters wars and other extraordinary circumstances if we try to look to the future without pre ##con ##ception ##s and in an open way we can fore ##see some of the general scenarios or individual moments that are more likely to occur [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 2695 3795 2344 2003 2242 13418 1996 5325 2008 8438 2003 2183 2083 2206 1996 21887 23350 6090 3207 7712 2038 2579 2006 2107 1037 3795 9812 2008 1037 2709 2000 1996 3653 4493 3663 2003 3432 5263 2065 1996 3659 1997 1996 7865 2003 2025 3030 2306 1037 3204 1998 1037 2431 2048 2706 1996 9575 2097 2468 20868 2890 14028 7028 1998 11585 1996 2878 2088 2344 2097 7859 2381 2038 2464 2714 6993 2008 2031 2042 3378 2007 3795 4094 18665 5233 1998 2060 9313 6214 2065 2057 3046 2000 2298 2000 1996 2925 2302 3653 8663 24422 2015 1998 1999 2019 2330 2126 2057 2064 18921 19763 2070 1997 1996 2236 16820 2030 3265 5312 2008 2024 2062 3497 2000 5258 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 2695 3795 2344 2003 2242 13418 1996 5325 2008 8438 2003 2183 2083 2206 1996 21887 23350 6090 3207 7712 2038 2579 2006 2107 1037 3795 9812 2008 1037 2709 2000 1996 3653 4493 3663 2003 3432 5263 2065 1996 3659 1997 1996 7865 2003 2025 3030 2306 1037 3204 1998 1037 2431 2048 2706 1996 9575 2097 2468 20868 2890 14028 7028 1998 11585 1996 2878 2088 2344 2097 7859 2381 2038 2464 2714 6993 2008 2031 2042 3378 2007 3795 4094 18665 5233 1998 2060 9313 6214 2065 2057 3046 2000 2298 2000 1996 2925 2302 3653 8663 24422 2015 1998 1999 2019 2330 2126 2057 2064 18921 19763 2070 1997 1996 2236 16820 2030 3265 5312 2008 2024 2062 3497 2000 5258 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] societies the effectiveness of the existing economic institutions and the competence of the elites in power globalization has failed ideological ##ly liberalism economically global networks and politically leadership of the western elites the sooner we recognize this particular turning point the more prepared we will be to face the new challenges the situation is comparable to that of the last days of the ussr the vast majority of the soviet ruling class even refused to consider moving to a new model of state governance and ideology and only a very small minority she realized the true nature of the crisis and was ready to adopt an alternative model in a bipolar world the collapse of one pole has left only the other and so the choice [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] societies the effectiveness of the existing economic institutions and the competence of the elites in power globalization has failed ideological ##ly liberalism economically global networks and politically leadership of the western elites the sooner we recognize this particular turning point the more prepared we will be to face the new challenges the situation is comparable to that of the last days of the ussr the vast majority of the soviet ruling class even refused to consider moving to a new model of state governance and ideology and only a very small minority she realized the true nature of the crisis and was ready to adopt an alternative model in a bipolar world the collapse of one pole has left only the other and so the choice [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 8384 1996 12353 1997 1996 4493 3171 4896 1998 1996 22219 1997 1996 27021 1999 2373 24370 2038 3478 17859 2135 26505 15318 3795 6125 1998 10317 4105 1997 1996 2530 27021 1996 10076 2057 6807 2023 3327 3810 2391 1996 2062 4810 2057 2097 2022 2000 2227 1996 2047 7860 1996 3663 2003 12435 2000 2008 1997 1996 2197 2420 1997 1996 10331 1996 6565 3484 1997 1996 3354 6996 2465 2130 4188 2000 5136 3048 2000 1037 2047 2944 1997 2110 10615 1998 13165 1998 2069 1037 2200 2235 7162 2016 3651 1996 2995 3267 1997 1996 5325 1998 2001 3201 2000 11092 2019 4522 2944 1999 1037 29398 2088 1996 7859 1997 2028 6536 2038 2187 2069 1996 2060 1998 2061 1996 3601 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 8384 1996 12353 1997 1996 4493 3171 4896 1998 1996 22219 1997 1996 27021 1999 2373 24370 2038 3478 17859 2135 26505 15318 3795 6125 1998 10317 4105 1997 1996 2530 27021 1996 10076 2057 6807 2023 3327 3810 2391 1996 2062 4810 2057 2097 2022 2000 2227 1996 2047 7860 1996 3663 2003 12435 2000 2008 1997 1996 2197 2420 1997 1996 10331 1996 6565 3484 1997 1996 3354 6996 2465 2130 4188 2000 5136 3048 2000 1037 2047 2944 1997 2110 10615 1998 13165 1998 2069 1037 2200 2235 7162 2016 3651 1996 2995 3267 1997 1996 5325 1998 2001 3201 2000 11092 2019 4522 2944 1999 1037 29398 2088 1996 7859 1997 2028 6536 2038 2187 2069 1996 2060 1998 2061 1996 3601 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the 1990s and the un ##ip ##olar world today what is coming down is the un ##ip ##olar world a fact that has been recognized in terms of ideology economy and political order by all the major world players china russia and almost everyone else and that has been welcomed with new attempts to gain independence and improve their conditions consequently the ruling elites are faced with a more complex problem the choice between a model that cr ##umble ##s into the abyss and the total unknown in which nothing can serve as a model for building the future one can imagine how even more than at the end of the soviet era the ruling elites will cl ##ing to global ##ism and its structures despite [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the 1990s and the un ##ip ##olar world today what is coming down is the un ##ip ##olar world a fact that has been recognized in terms of ideology economy and political order by all the major world players china russia and almost everyone else and that has been welcomed with new attempts to gain independence and improve their conditions consequently the ruling elites are faced with a more complex problem the choice between a model that cr ##umble ##s into the abyss and the total unknown in which nothing can serve as a model for building the future one can imagine how even more than at the end of the soviet era the ruling elites will cl ##ing to global ##ism and its structures despite [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 4134 1998 1996 4895 11514 19478 2088 2651 2054 2003 2746 2091 2003 1996 4895 11514 19478 2088 1037 2755 2008 2038 2042 3858 1999 3408 1997 13165 4610 1998 2576 2344 2011 2035 1996 2350 2088 2867 2859 3607 1998 2471 3071 2842 1998 2008 2038 2042 10979 2007 2047 4740 2000 5114 4336 1998 5335 2037 3785 8821 1996 6996 27021 2024 4320 2007 1037 2062 3375 3291 1996 3601 2090 1037 2944 2008 13675 26607 2015 2046 1996 22159 1998 1996 2561 4242 1999 2029 2498 2064 3710 2004 1037 2944 2005 2311 1996 2925 2028 2064 5674 2129 2130 2062 2084 2012 1996 2203 1997 1996 3354 3690 1996 6996 27021 2097 18856 2075 2000 3795 2964 1998 2049 5090 2750 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 4134 1998 1996 4895 11514 19478 2088 2651 2054 2003 2746 2091 2003 1996 4895 11514 19478 2088 1037 2755 2008 2038 2042 3858 1999 3408 1997 13165 4610 1998 2576 2344 2011 2035 1996 2350 2088 2867 2859 3607 1998 2471 3071 2842 1998 2008 2038 2042 10979 2007 2047 4740 2000 5114 4336 1998 5335 2037 3785 8821 1996 6996 27021 2024 4320 2007 1037 2062 3375 3291 1996 3601 2090 1037 2944 2008 13675 26607 2015 2046 1996 22159 1998 1996 2561 4242 1999 2029 2498 2064 3710 2004 1037 2944 2005 2311 1996 2925 2028 2064 5674 2129 2130 2062 2084 2012 1996 2203 1997 1996 3354 3690 1996 6996 27021 2097 18856 2075 2000 3795 2964 1998 2049 5090 2750 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] even within the elite how the relationship between global ##ists and post global ##ists will develop is difficult to imagine but it is already possible to anti ##ci ##pate in general terms the main points of the post global ##ist reality 1 the open society will become a closed society sovereignty will rise to the rank of highest value of absolute value the good will be declared to be the salvation and vital support of a particular people within a concrete state power will be legitimate only if it can deal with this task first of all save peoples lives in the context of a pan ##de ##mic and the catastrophic processes that accompany it and then organize a political economic and ideological structure that allows [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] even within the elite how the relationship between global ##ists and post global ##ists will develop is difficult to imagine but it is already possible to anti ##ci ##pate in general terms the main points of the post global ##ist reality 1 the open society will become a closed society sovereignty will rise to the rank of highest value of absolute value the good will be declared to be the salvation and vital support of a particular people within a concrete state power will be legitimate only if it can deal with this task first of all save peoples lives in the context of a pan ##de ##mic and the catastrophic processes that accompany it and then organize a political economic and ideological structure that allows [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2130 2306 1996 7069 2129 1996 3276 2090 3795 5130 1998 2695 3795 5130 2097 4503 2003 3697 2000 5674 2021 2009 2003 2525 2825 2000 3424 6895 17585 1999 2236 3408 1996 2364 2685 1997 1996 2695 3795 2923 4507 1015 1996 2330 2554 2097 2468 1037 2701 2554 12601 2097 4125 2000 1996 4635 1997 3284 3643 1997 7619 3643 1996 2204 2097 2022 4161 2000 2022 1996 12611 1998 8995 2490 1997 1037 3327 2111 2306 1037 5509 2110 2373 2097 2022 11476 2069 2065 2009 2064 3066 2007 2023 4708 2034 1997 2035 3828 7243 3268 1999 1996 6123 1997 1037 6090 3207 7712 1998 1996 23546 6194 2008 12673 2009 1998 2059 10939 1037 2576 3171 1998 17859 3252 2008 4473 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2130 2306 1996 7069 2129 1996 3276 2090 3795 5130 1998 2695 3795 5130 2097 4503 2003 3697 2000 5674 2021 2009 2003 2525 2825 2000 3424 6895 17585 1999 2236 3408 1996 2364 2685 1997 1996 2695 3795 2923 4507 1015 1996 2330 2554 2097 2468 1037 2701 2554 12601 2097 4125 2000 1996 4635 1997 3284 3643 1997 7619 3643 1996 2204 2097 2022 4161 2000 2022 1996 12611 1998 8995 2490 1997 1037 3327 2111 2306 1037 5509 2110 2373 2097 2022 11476 2069 2065 2009 2064 3066 2007 2023 4708 2034 1997 2035 3828 7243 3268 1999 1996 6123 1997 1037 6090 3207 7712 1998 1996 23546 6194 2008 12673 2009 1998 2059 10939 1037 2576 3171 1998 17859 3252 2008 4473 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] first of all the main and absolute priority of this country and this people no other ideological consideration can pre ##va ##il on this principle 2 a closed society must be auto ##cratic this means that it must be self sufficient and independent of external suppliers in the first place regarding food industrial production in its monetary and financial system and in relation to its military power all of this will become the top priority in the fight against the epidemic when states are forced to close but in the post global ##ist world this will be a permanent feature if global ##ists view it as a temporary measure post global ##ists should on the contrary prepare to make it a strategic priority 3 self su [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] first of all the main and absolute priority of this country and this people no other ideological consideration can pre ##va ##il on this principle 2 a closed society must be auto ##cratic this means that it must be self sufficient and independent of external suppliers in the first place regarding food industrial production in its monetary and financial system and in relation to its military power all of this will become the top priority in the fight against the epidemic when states are forced to close but in the post global ##ist world this will be a permanent feature if global ##ists view it as a temporary measure post global ##ists should on the contrary prepare to make it a strategic priority 3 self su [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2034 1997 2035 1996 2364 1998 7619 9470 1997 2023 2406 1998 2023 2111 2053 2060 17859 9584 2064 3653 3567 4014 2006 2023 6958 1016 1037 2701 2554 2442 2022 8285 17510 2023 2965 2008 2009 2442 2022 2969 7182 1998 2981 1997 6327 20141 1999 1996 2034 2173 4953 2833 3919 2537 1999 2049 12194 1998 3361 2291 1998 1999 7189 2000 2049 2510 2373 2035 1997 2023 2097 2468 1996 2327 9470 1999 1996 2954 2114 1996 16311 2043 2163 2024 3140 2000 2485 2021 1999 1996 2695 3795 2923 2088 2023 2097 2022 1037 4568 3444 2065 3795 5130 3193 2009 2004 1037 5741 5468 2695 3795 5130 2323 2006 1996 10043 7374 2000 2191 2009 1037 6143 9470 1017 2969 10514 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2034 1997 2035 1996 2364 1998 7619 9470 1997 2023 2406 1998 2023 2111 2053 2060 17859 9584 2064 3653 3567 4014 2006 2023 6958 1016 1037 2701 2554 2442 2022 8285 17510 2023 2965 2008 2009 2442 2022 2969 7182 1998 2981 1997 6327 20141 1999 1996 2034 2173 4953 2833 3919 2537 1999 2049 12194 1998 3361 2291 1998 1999 7189 2000 2049 2510 2373 2035 1997 2023 2097 2468 1996 2327 9470 1999 1996 2954 2114 1996 16311 2043 2163 2024 3140 2000 2485 2021 1999 1996 2695 3795 2923 2088 2023 2097 2022 1037 4568 3444 2065 3795 5130 3193 2009 2004 1037 5741 5468 2695 3795 5130 2323 2006 1996 10043 7374 2000 2191 2009 1037 6143 9470 1017 2969 10514 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eD_Bwc2_gJIw",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-VDXu0sfg0OS",
        "colab": {}
      },
      "source": [
        "\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg,\n",
        "            }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs, output_layer) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels,\n",
        "          'pooled_output': output_layer\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WooSh5c5hsKu",
        "colab": {}
      },
      "source": [
        "OUTPUT_DIR = '/bert_news_category'\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = True #@param {type:\"boolean\"}\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2IDk8ZlihWPz",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1.0\n",
        "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 300\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JbqcFeS6iCSV",
        "colab": {}
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3uOlQDQFiGaR",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "12sypRbaiSZV",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7GuFi1jSkKBJ",
        "colab": {}
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pS4P13JOioN9",
        "colab": {}
      },
      "source": [
        "#Evaluating the model with Validation set\n",
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}